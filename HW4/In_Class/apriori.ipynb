{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0       1     2       3       4       5       6\n",
      "0   Bread    Wine  Eggs    Meat  Cheese  Pencil  Diaper\n",
      "1   Bread  Cheese  Meat  Diaper    Wine    Milk  Pencil\n",
      "2  Cheese    Meat  Eggs    Milk    Wine     NaN     NaN\n",
      "3  Cheese    Meat  Eggs    Milk    Wine     NaN     NaN\n",
      "4    Meat  Pencil  Wine     NaN     NaN     NaN     NaN\n",
      "Unique items: ['Bread' 'Cheese' 'Meat' 'Eggs' 'Wine' 'Bagel' 'Pencil' 'Diaper' 'Milk']\n",
      "{'Bagel': 0, 'Milk': 0, 'Bread': 1, 'Meat': 1, 'Pencil': 1, 'Cheese': 1, 'Eggs': 1, 'Diaper': 1, 'Wine': 1}\n",
      "Processing 4 combinations | Sampling itemset size 4 3\n",
      "frequent Items:\n",
      "    support  itemsets\n",
      "0  0.425397   (Bagel)\n",
      "1  0.501587    (Milk)\n",
      "2  0.504762   (Bread)\n",
      "3  0.476190    (Meat)\n",
      "4  0.361905  (Pencil)\n",
      "5  0.501587  (Cheese)\n",
      "6  0.438095    (Eggs)\n",
      "Rules: \n",
      "  antecedents consequents  antecedent support  consequent support   support  \\\n",
      "0     (Bagel)     (Bread)            0.425397            0.504762  0.279365   \n",
      "1    (Cheese)      (Milk)            0.501587            0.501587  0.304762   \n",
      "2      (Milk)    (Cheese)            0.501587            0.501587  0.304762   \n",
      "3      (Meat)    (Cheese)            0.476190            0.501587  0.323810   \n",
      "4    (Cheese)      (Meat)            0.501587            0.476190  0.323810   \n",
      "\n",
      "   confidence      lift  leverage  conviction  \n",
      "0    0.656716  1.301042  0.064641    1.442650  \n",
      "1    0.607595  1.211344  0.053172    1.270148  \n",
      "2    0.607595  1.211344  0.053172    1.270148  \n",
      "3    0.680000  1.355696  0.084958    1.557540  \n",
      "4    0.645570  1.355696  0.084958    1.477891  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zaid\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:111: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.read_csv('retail_dataset.csv', sep=',')\n",
    "\n",
    "## Print top 5 rows\n",
    "# print(df.head(5))\n",
    "\n",
    "\n",
    "#Each row of the dataset represents items that were purchased together on the same day at the same store.\n",
    "# The dataset is a sparse dataset as relatively high percentage of data is NA or NaN or equivalent.\n",
    "#These NaNs make it hard to read the table.\n",
    "# Let’s find out how many unique items are actually there in the table.\n",
    "\n",
    "items = (df['0'].unique())\n",
    "print(\"Unique items:\", items)\n",
    "\n",
    "#There are only 9 items in total that make up the entire dataset.\n",
    "\n",
    "\n",
    "#############Data Preprocessing\n",
    "\n",
    "#To make use of the apriori module given by mlxtend library, we need to convert the dataset according to\n",
    "# it’s liking. apriori module requires a dataframe that has either 0 and 1 or True and False as data.\n",
    "# The data we have is all string (name of items), we need to One Hot Encode the data.\n",
    "\n",
    "\n",
    "itemset = set(items)\n",
    "encoded_vals = []\n",
    "for index, row in df.iterrows():\n",
    "    rowset = set(row)\n",
    "    labels = {}\n",
    "    uncommons = list(itemset - rowset)\n",
    "    commons = list(itemset.intersection(rowset))\n",
    "    for uc in uncommons:\n",
    "        labels[uc] = 0\n",
    "    for com in commons:\n",
    "        labels[com] = 1\n",
    "    encoded_vals.append(labels)\n",
    "\n",
    "print(encoded_vals[0])\n",
    "ohe_df = pd.DataFrame(encoded_vals)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################### Applying Apriori\n",
    "\n",
    "freq_items = apriori(ohe_df, min_support=0.2, use_colnames=True, verbose=1)\n",
    "print(\"frequent Items:\")\n",
    "print(freq_items.head(7))\n",
    "\n",
    "\n",
    "##########################  Mining Association Rules\n",
    "\n",
    "rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.6)\n",
    "print(\"Rules: \")\n",
    "print(rules.head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86b7ff701e4d3656eb4d12e4236d9d8e1f9da7ffae7f05b636f9f1f1fb530650"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
